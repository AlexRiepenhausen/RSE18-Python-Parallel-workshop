{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first mini-tutorial, we are going to have a look at Python's `multiprocessing` module. This is a built-in module within the core Python modules and does not need any further installation.\n",
    "\n",
    "Multiprocessing is a useful approach to parallelism where you can divide a task into separate sub-tasks that require minimal communication between tasks during computation time. Multiprocessing avoids the Python GIL issue by creating separate operating-system level processes, each running an instance of a Python interpreter. If tasks require commumication between each OS-level process, the multiprocessing module has functionality to coordinate this. However, multiprocessing that requires significant communications between tasks is likely to incur a lot of additional overhead.\n",
    "\n",
    "A common use of the `multiprocessing` module is to parallelise a task over a set of operating system processes for a CPU-bound problem. I/O bound problems can also be solved using `multiprocessing`, though there are other alternatives for this which are more appropriate. (We do not cover them in these tutorials, but you may wish to investigate `asyncio`, which is standard from Python 3.4 onwards.)\n",
    "\n",
    "In this example, we are going to introduce a set of examples that explore the multiprocessing module by calculating pi using a Monte Carlo approach. It's a simple problem that parallelises easily, although it may not be the most efficient way of actually calculating pi in practice! \n",
    "\n",
    "## Estimating Pi with a parallel Monte Carlo method\n",
    "\n",
    "An interesting way to calculate pi is to imagine throwing darts or arrows at a target with a circle printed on it. If we assume where we hit on the target is random (we are not veryu good archers or darts players) then the relationship between the number of arrows hitting inside the circle compared to outside the circle can be used to help us estimate pi.\n",
    "\n",
    "The workload can be split evenly across a number of processes, each one running a separate Python instance, on a separate CPU core.\n",
    "\n",
    "To get a good estimate of pi using this method, we need to through around 10,000 darts at our target, which will give us an estimate to the first three decimal places. There are of course much better methods for estimating pi, but this is a nice example of using the `multiprocessing` module.\n",
    "\n",
    "With the Monte Carlo method, we can use the Pythagorean principle to test if our dart has landed inside the circle.\n",
    "\n",
    "`sqrt(x^2 + y^2) <= 1^2`\n",
    "\n",
    "https://en.wikipedia.org/wiki/Pythagorean_theorem\n",
    "\n",
    "Since we are using the _unit circle_ (The circle segment selected by drawing a square around the circle from the centre - basically a quarter of the full circle) we can simplify this further by taking out the square root operation:\n",
    "\n",
    "`x^2 + y^2 <= 1`\n",
    "\n",
    "The code to calculate this is as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def estimate_number_points_in_quarter_circle(number_estimates):\n",
    "    number_trials_in_quarter_circle = 0\n",
    "    for step in range(int(number_estimates)):\n",
    "        x = random.uniform(0, 1)\n",
    "        y = random.uniform(0, 1)\n",
    "        is_in_unit_circle = x * x + y * y <= 1.0\n",
    "        number_trials_in_quarter_circle += is_in_unit_circle\n",
    "    return number_trials_in_quarter_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Python implementation of our pi estimator using the circle method.\n",
    "\n",
    "To solve this problem with parallelism, running a simulation with 10,000 dart throws, we could apportion the work between the number of CPU cores we have available to us, and do the computation in parallel. So, on a four-core CPU system, we could do 2,500 dart throws on each CPU core. \n",
    "\n",
    "Now we need to use the `multiprocessing` module to apportion our work in the function above between separate parallel processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we import the Pool class from the module. `Pool` wraps the the `Process` class API representing an OS-level preocess into a convenient pool of worker tasks that share a chunk of work and return an aggregated result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "number_samples_in_total = 10000\n",
    "number_parallel_blocks = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a task pool with a given number of processes to create. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making 625.0 samples per worker task\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(processes=number_parallel_blocks)\n",
    "\n",
    "# Calculate how many samples to send to each worker task, based on the number of parallel block\n",
    "number_samples_per_worker_task = number_samples_in_total / number_parallel_blocks\n",
    "\n",
    "print(\"Making {} samples per worker task\".format(number_samples_per_worker_task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a list containing the number of estimates divided by the number of workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_trials_per_process = [number_samples_per_worker_task] * number_parallel_blocks\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next bit is where we use multiprocessing to distribute the task evenly among the worker processes. We do this using the `pool.map` method, passing the function we want to parallelise: our dart throwing pi estimator, `estimate_number_points_in_quarter_circle`, and the argument it takes: `number_estimates`. Because we are distributing this task over `n` processes, we pass the value we calculated for: `number_of_trials_per_process`.\n",
    "\n",
    "The value we get back from the `pool.map` function will contain the same number of results as `number_trials_per_process`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_in_unit_circles = pool.map(estimate_number_points_in_quarter_circle, number_trials_per_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, to obtain our final estimate of pi, we simply sum up this list of results from each process, multiply by four (to get the full circle from our quarter circle) and divide by the total number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated pi 3.1768\n",
      "Time Delta: 1.994596242904663\n"
     ]
    }
   ],
   "source": [
    "pi_estimate = sum(number_in_unit_circles) * 4 / number_samples_in_total\n",
    "\n",
    "# Let's look at the results and how long it took\n",
    "print(\"Estimated pi {}\".format(pi_estimate))\n",
    "print(\"Time Delta: {}\".format(time.time()-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you have a reasonable looking value of pi!\n",
    "\n",
    "Try changing the initial paramters for number of parallel blocks and number of samples. \n",
    "\n",
    "Do you get a speed up if you keep increasing the `number_parallel_blocks`? _Hint: It will be dependent on the machine you are running this on, and the number of CPU cores it has._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
