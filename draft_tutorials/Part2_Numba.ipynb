{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Numba\n",
    "\n",
    "Numba is another Python package designed to offer increased performance with Python applications that use a lot of `numpy` code for computation. Numba is a 'just-in-time' compiler for numpy code - it works by compiling your numpy code at runtime into optimised machine code. \n",
    "\n",
    "Numba works best on numpy code that can be encapsulated neatly into separate, minimal functions, such as performing operations on arrays, or code with loops. Numba is most commonly used with python decorators, which are placed above the function you wish to optimise through just-in-time compilation.\n",
    "\n",
    "You will likely see perfomance gains in most numpy code through using numba with its default options and using the commonly applied decorators `@jit`, however, these decorators themselves do not cause numba to run parallel computation (The speed up initially comes from having \"jit-ted\" code.) \n",
    "\n",
    "To exploit the features of parallelism in numba, we have to go beyond the basics of numba, but first lets look at some simple examples of jitted code with numba:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.arange(100000000).reshape(10000, 10000)\n",
    "\n",
    "@jit(nopython=True) # Set \"nopython\" mode for best performance\n",
    "def go_fast(a): # Function is compiled to machine code when called the first time\n",
    "    trace = 0\n",
    "    for i in range(a.shape[0]):   # Numba likes loops\n",
    "        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n",
    "    return a + trace              # Numba likes NumPy broadcasting\n",
    "\n",
    "# You can optionally run the function the first time to compile it\n",
    "result = go_fast(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not using a jupyter notebook, you can uncomment the timing measurements below, or use a profiling tool of your choice. (I am using the built in feature of jupyter notebooks that allows us to time the texecution of a notebook cell: `%%timeit`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 ms ± 8.23 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# If you are not using a jupyter notebook, you can uncomment the timing measurements below:\n",
    "#t1 = time.time()\n",
    "result = go_fast(x)\n",
    "#t2 = time.time()\n",
    "#delta_t = t2 - t1\n",
    "\n",
    "#print(\"Time taken: {}\".format(delta_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for comparison, the **non-numba** version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.arange(100000000).reshape(10000, 10000)\n",
    "\n",
    "def go_slow(a): # Function is run as standard Python/Numpy code\n",
    "    trace = 0\n",
    "    for i in range(a.shape[0]):   \n",
    "        trace += np.tanh(a[i, i]) \n",
    "    return a + trace              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373 ms ± 6.91 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#t1 = time.time()\n",
    "result = go_slow(x)\n",
    "#t2 = time.time()\n",
    "#delta_t = t2 - t1\n",
    "\n",
    "#print(\"Time taken: {}\".format(delta_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of results so far:\n",
    "\n",
    "The adding of a numba decorator `@jit` gives us fairly minor speed up when the plain numpy code is jitted:\n",
    "\n",
    " - Plain numpy: 304ms\n",
    " - Numba numpy: 373ms\n",
    "\n",
    "Let's see if we can now get some better performance using the parallel options in numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel numba\n",
    "\n",
    "To make use of parallel methods with numba, we use the `nogil` feature. You will also see the `nogil` feature refered to in Cython when talking about parallelisation techniques. Nogil allows us to disable the python GIL given conditions: namely when we are using numba-optimised code that only operaties on native types and variables (rather than Python objects).\n",
    "\n",
    "When using the `@jit` decorator, we pass an additional keyword argument: `@jit(nogil=True)` to use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.arange(100000000).reshape(10000, 10000)\n",
    "\n",
    "@jit(nopython=True, nogil=True, parallel=True) # Set \"nopython\" mode for best performance\n",
    "def go_fast_nogil(a): # Function is compiled to machine code when called the first time\n",
    "    trace = 0\n",
    "    for i in range(a.shape[0]):   # Numba likes loops\n",
    "        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n",
    "    return a + trace              # Numba likes NumPy broadcasting\n",
    "\n",
    "# You can optionally run the function the first time to compile it\n",
    "result = go_fast_nogil(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 ms ± 2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = go_fast_nogil(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of results so far:\n",
    "\n",
    "The adding of arguments `nogil=True` and `parallel=True` to to numba decorator `@jit` gives us a much better speed up. The results from my (4 core) laptop were:\n",
    "\n",
    " - Plain numpy: 304ms\n",
    " - Numba numpy: 373ms\n",
    " - __Numba + `nogil` + `parallel`: 170ms__\n",
    "\n",
    "Try it with you own machine and see if you get comparable results.\n",
    "\n",
    "## More details on how numba works\n",
    "\n",
    "We won't go into the details of how numba works in this mini-tutorial, but basically it uses clever heuristics to determine if a loop or other constructs in a function can be parallelised. This means you may not always get speedup using the `parallel=True` argument, as numba's internal logic may have decided that the loop cannot be parallelised or is not worth parallelising. The aim of the numba module is to make parallelisation easy to the end user (by just adding a decorator with a few keyword arguments) but at the expense of hiding a lot of the details of what is going on 'under the hood'. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A more advanced example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy (1 thread)        34 ms\n",
      "numba (1 thread)       119 ms\n",
      "numba (4 threads)       46 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.00112562,  4.68331271, 38.09321246, ...,  7.84046845,\n",
       "       13.55508374,  4.41382201])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import threading\n",
    "from timeit import repeat\n",
    "\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "nthreads = 4\n",
    "size = 10**6\n",
    "\n",
    "def func_np(a, b):\n",
    "    \"\"\"\n",
    "    Control function using Numpy.\n",
    "    \"\"\"\n",
    "    return np.exp(2.1 * a + 3.2 * b)\n",
    "\n",
    "@jit('void(double[:], double[:], double[:])', nopython=True, nogil=True)\n",
    "def inner_func_nb(result, a, b):\n",
    "    \"\"\"\n",
    "    Function under test.\n",
    "    \"\"\"\n",
    "    for i in range(len(result)):\n",
    "        result[i] = math.exp(2.1 * a[i] + 3.2 * b[i])\n",
    "\n",
    "def timefunc(correct, s, func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Benchmark *func* and print out its runtime.\n",
    "    \"\"\"\n",
    "    print(s.ljust(20), end=\" \")\n",
    "    # Make sure the function is compiled before we start the benchmark\n",
    "    res = func(*args, **kwargs)\n",
    "    if correct is not None:\n",
    "        assert np.allclose(res, correct), (res, correct)\n",
    "    # time it\n",
    "    print('{:>5.0f} ms'.format(min(repeat(lambda: func(*args, **kwargs),\n",
    "                                          number=5, repeat=2)) * 1000))\n",
    "    return res\n",
    "\n",
    "def make_singlethread(inner_func):\n",
    "    \"\"\"\n",
    "    Run the given function inside a single thread.\n",
    "    \"\"\"\n",
    "    def func(*args):\n",
    "        length = len(args[0])\n",
    "        result = np.empty(length, dtype=np.float64)\n",
    "        inner_func(result, *args)\n",
    "        return result\n",
    "    return func\n",
    "\n",
    "def make_multithread(inner_func, numthreads):\n",
    "    \"\"\"\n",
    "    Run the given function inside *numthreads* threads, splitting its\n",
    "    arguments into equal-sized chunks.\n",
    "    \"\"\"\n",
    "    def func_mt(*args):\n",
    "        length = len(args[0])\n",
    "        result = np.empty(length, dtype=np.float64)\n",
    "        args = (result,) + args\n",
    "        chunklen = (length + numthreads - 1) // numthreads\n",
    "        # Create argument tuples for each input chunk\n",
    "        chunks = [[arg[i * chunklen:(i + 1) * chunklen] for arg in args]\n",
    "                  for i in range(numthreads)]\n",
    "        # Spawn one thread per chunk\n",
    "        threads = [threading.Thread(target=inner_func, args=chunk)\n",
    "                   for chunk in chunks]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        return result\n",
    "    return func_mt\n",
    "\n",
    "\n",
    "func_nb = make_singlethread(inner_func_nb)\n",
    "func_nb_mt = make_multithread(inner_func_nb, nthreads)\n",
    "\n",
    "a = np.random.rand(size)\n",
    "b = np.random.rand(size)\n",
    "\n",
    "correct = timefunc(None, \"numpy (1 thread)\", func_np, a, b)\n",
    "timefunc(correct, \"numba (1 thread)\", func_nb, a, b)\n",
    "timefunc(correct, \"numba (%d threads)\" % nthreads, func_nb_mt, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
